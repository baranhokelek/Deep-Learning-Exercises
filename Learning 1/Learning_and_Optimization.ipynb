{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import elementwise_grad as egrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull data\n",
    "\n",
    "fname = pwd + '/data_banknote_authentication.txt'\n",
    "banknote_data = np.loadtxt(fname, delimiter = ',')\n",
    "banknote_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(y):\n",
    "    b = np.zeros((y.size, y.max()+1))\n",
    "    b[np.arange(y.size),y] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of:\n",
      "x_train: (4, 919),\ty_train: (2, 919),\tx_test: (4, 453),\ty_test: (2, 453)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train & test datasets\n",
    "\n",
    "banknote_x = banknote_data[:, :4]\n",
    "banknote_y = onehot(banknote_data[:, 4].astype(int))\n",
    "\n",
    "banknote_x_train, banknote_x_test, banknote_y_train, banknote_y_test = train_test_split(banknote_x, banknote_y, test_size=0.33, random_state=42)\n",
    "banknote_x_train = banknote_x_train.transpose()\n",
    "banknote_x_test = banknote_x_test.transpose()\n",
    "\n",
    "banknote_y_train = banknote_y_train.transpose()\n",
    "banknote_y_test = banknote_y_test.transpose()\n",
    "print(f'Sizes of:\\nx_train: {banknote_x_train.shape},\\ty_train: {banknote_y_train.shape},\\tx_test: {banknote_x_test.shape},\\ty_test: {banknote_y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTRN = len(banknote_x_train[0])\n",
    "NTST = len(banknote_x_test[0])\n",
    "\n",
    "XDIM = len(banknote_x_train)\n",
    "YDIM = len(banknote_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81474619, 0.9805949 , 0.1390099 , 0.55829626],\n",
       "       [0.71173289, 0.67536457, 0.95749833, 0.70042555]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(YDIM, XDIM)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â Initial predictions\n",
    "ip = np.transpose([np.argmax(np.dot(w, banknote_x_train[:,i])) for i in range(NTRN)])\n",
    "print(ip.shape)\n",
    "ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct answers\n",
    "ca = np.transpose([np.argmax(banknote_y_train[:,i]) for i in range(NTRN)])\n",
    "print(ca.shape)\n",
    "ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def acc(w, x, y):\n",
    "    return np.mean(np.argmax(np.dot(w, x), axis=0) == np.argmax(y, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5745375408052231 0.543046357615894\n"
     ]
    }
   ],
   "source": [
    "print(acc(w, banknote_x_train, banknote_y_train), acc(w, banknote_x_test, banknote_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote_x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(algo, x, y, num_epochs = int(2**20)):\n",
    "    w = np.zeros((y.shape[0], x.shape[0]))\n",
    "    num_examples = x.shape[1]\n",
    "    next_print = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        i = np.random.randint(0, num_examples-1)\n",
    "        algo(w, x[:, i], y[:, i])\n",
    "        if epoch == next_print:\n",
    "            print(f'Iteration: {epoch}\\tAccuracy: {acc(w, x, y)}\\tW-norm: {np.linalg.norm(w)}')\n",
    "            next_print = min(2*epoch, num_epochs)\n",
    "    print(f'Final W: {w}')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(w, x, y):\n",
    "    guess = np.argmax(np.dot(w, x))\n",
    "    correct_ans = np.argmax(y)\n",
    "    if guess != correct_ans:\n",
    "        w[correct_ans, :] += x\n",
    "        w[guess, :] -= x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.5495103373231773\tW-norm: 0.0\n",
      "Iteration: 2\tAccuracy: 0.5495103373231773\tW-norm: 0.0\n",
      "Iteration: 4\tAccuracy: 0.7486398258977149\tW-norm: 17.98002103970404\n",
      "Iteration: 8\tAccuracy: 0.7486398258977149\tW-norm: 17.98002103970404\n",
      "Iteration: 16\tAccuracy: 0.8422198041349293\tW-norm: 15.855448441877385\n",
      "Iteration: 32\tAccuracy: 0.8258977149075082\tW-norm: 20.857371338772104\n",
      "Iteration: 64\tAccuracy: 0.9042437431991295\tW-norm: 26.0578297028454\n",
      "Iteration: 128\tAccuracy: 0.8955386289445049\tW-norm: 34.94874851606981\n",
      "Iteration: 256\tAccuracy: 0.9445048966267682\tW-norm: 38.190544060445276\n",
      "Iteration: 512\tAccuracy: 0.9521218715995647\tW-norm: 43.13281429351264\n",
      "Iteration: 1024\tAccuracy: 0.941240478781284\tW-norm: 57.63097639142704\n",
      "Iteration: 2048\tAccuracy: 0.8803046789989118\tW-norm: 77.12119455998047\n",
      "Iteration: 4096\tAccuracy: 0.9542981501632208\tW-norm: 87.91508819335458\n",
      "Iteration: 8192\tAccuracy: 0.9466811751904244\tW-norm: 99.01172486174328\n",
      "Iteration: 16384\tAccuracy: 0.9532100108813928\tW-norm: 103.2166333883995\n",
      "Iteration: 32768\tAccuracy: 0.9640914036996736\tW-norm: 101.82286577236361\n",
      "Iteration: 65536\tAccuracy: 0.9597388465723613\tW-norm: 95.55496640563938\n",
      "Iteration: 131072\tAccuracy: 0.9455930359085963\tW-norm: 98.14451079256536\n",
      "Iteration: 262144\tAccuracy: 0.9630032644178455\tW-norm: 92.73074444940077\n",
      "Iteration: 524288\tAccuracy: 0.9630032644178455\tW-norm: 107.08347538869181\n",
      "Final W: [[ 47.9869922  36.527913   30.527509   19.7001968]\n",
      " [-47.9869922 -36.527913  -30.527509  -19.7001968]]\n"
     ]
    }
   ],
   "source": [
    "wperceptron = train(perceptron, banknote_x_train, banknote_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaline(w, x, y, lr = 0.0001):\n",
    "    error = np.dot(w, x) - y\n",
    "    w -= lr * np.outer(error, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.6594124047878128\tW-norm: 0.0013387284289652836\n",
      "Iteration: 2\tAccuracy: 0.6387377584330794\tW-norm: 0.002539958652798517\n",
      "Iteration: 4\tAccuracy: 0.6496191512513602\tW-norm: 0.003293002875756407\n",
      "Iteration: 8\tAccuracy: 0.6855277475516867\tW-norm: 0.004332023188808136\n",
      "Iteration: 16\tAccuracy: 0.6702937976060935\tW-norm: 0.0072471552739841\n",
      "Iteration: 32\tAccuracy: 0.6572361262241567\tW-norm: 0.013278033235740193\n",
      "Iteration: 64\tAccuracy: 0.6670293797606094\tW-norm: 0.02344093846172342\n",
      "Iteration: 128\tAccuracy: 0.6942328618063112\tW-norm: 0.03899006126535003\n",
      "Iteration: 256\tAccuracy: 0.73449401523395\tW-norm: 0.06545817508019897\n",
      "Iteration: 512\tAccuracy: 0.8607181719260065\tW-norm: 0.10154600411907813\n",
      "Iteration: 1024\tAccuracy: 0.9151251360174102\tW-norm: 0.15620650029336877\n",
      "Iteration: 2048\tAccuracy: 0.9445048966267682\tW-norm: 0.21201066951523595\n",
      "Iteration: 4096\tAccuracy: 0.9466811751904244\tW-norm: 0.24964101951190132\n",
      "Iteration: 8192\tAccuracy: 0.9488574537540805\tW-norm: 0.2641323385041421\n",
      "Iteration: 16384\tAccuracy: 0.9445048966267682\tW-norm: 0.27301377378596503\n",
      "Iteration: 32768\tAccuracy: 0.9434167573449401\tW-norm: 0.2696904607925149\n",
      "Iteration: 65536\tAccuracy: 0.9499455930359086\tW-norm: 0.26955998108174506\n",
      "Iteration: 131072\tAccuracy: 0.9423286180631121\tW-norm: 0.27485286823625515\n",
      "Iteration: 262144\tAccuracy: 0.9510337323177367\tW-norm: 0.2732254327071722\n",
      "Iteration: 524288\tAccuracy: 0.9423286180631121\tW-norm: 0.27277835426186836\n",
      "Final W: [[ 0.1628905   0.09391966  0.13815756 -0.02764752]\n",
      " [-0.06001454 -0.01810682  0.02515523 -0.11858292]]\n"
     ]
    }
   ],
   "source": [
    "wadaline = train(adaline, banknote_x_train, banknote_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(w, x, y, lr = 0.01):\n",
    "    probs = np.exp(np.dot(w, x))\n",
    "    probs /= np.sum(probs)\n",
    "    error = probs - y\n",
    "    w -= lr * np.outer(error, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.6594124047878128\tW-norm: 0.07181362484524383\n",
      "Iteration: 2\tAccuracy: 0.6550598476605005\tW-norm: 0.11057691602017777\n",
      "Iteration: 4\tAccuracy: 0.6507072905331882\tW-norm: 0.1461294334632158\n",
      "Iteration: 8\tAccuracy: 0.6833514689880305\tW-norm: 0.18256762501025048\n",
      "Iteration: 16\tAccuracy: 0.8052230685527747\tW-norm: 0.20736107309271445\n",
      "Iteration: 32\tAccuracy: 0.8335146898803046\tW-norm: 0.30548225414236085\n",
      "Iteration: 64\tAccuracy: 0.9303590859630033\tW-norm: 0.44392470443105697\n",
      "Iteration: 128\tAccuracy: 0.9466811751904244\tW-norm: 0.6238812189672804\n",
      "Iteration: 256\tAccuracy: 0.9357997823721437\tW-norm: 0.8610340698032355\n",
      "Iteration: 512\tAccuracy: 0.955386289445049\tW-norm: 1.119461457074803\n",
      "Iteration: 1024\tAccuracy: 0.9608269858541894\tW-norm: 1.3886828354333869\n",
      "Iteration: 2048\tAccuracy: 0.9488574537540805\tW-norm: 1.729861317845446\n",
      "Iteration: 4096\tAccuracy: 0.9608269858541894\tW-norm: 2.1290827803767414\n",
      "Iteration: 8192\tAccuracy: 0.9608269858541894\tW-norm: 2.518999142070026\n",
      "Iteration: 16384\tAccuracy: 0.9630032644178455\tW-norm: 2.875686380575695\n",
      "Iteration: 32768\tAccuracy: 0.9619151251360174\tW-norm: 2.966523495583907\n",
      "Iteration: 65536\tAccuracy: 0.9608269858541894\tW-norm: 3.077881349765919\n",
      "Iteration: 131072\tAccuracy: 0.9630032644178455\tW-norm: 3.151243805499771\n",
      "Iteration: 262144\tAccuracy: 0.9630032644178455\tW-norm: 2.9953077459344044\n",
      "Iteration: 524288\tAccuracy: 0.956474428726877\tW-norm: 3.0757008791155234\n",
      "Final W: [[ 1.54072919  1.03093524  1.10830703  0.51012003]\n",
      " [-1.54072919 -1.03093524 -1.10830703 -0.51012003]]\n"
     ]
    }
   ],
   "source": [
    "wsoftmax = train(softmax, banknote_x_train, banknote_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(loss, x, y, lr = 1, num_epochs = int(2**20)):\n",
    "    w = np.zeros((banknote_y_train.shape[0], banknote_x_train.shape[0]))\n",
    "    num_examples = banknote_x_train.shape[1]\n",
    "    next_print = 1\n",
    "    for epoch in range(num_epochs + 1):\n",
    "        i = random.randint(0, num_examples-1)\n",
    "        loss_grad = grad(loss)\n",
    "        del_w = loss_grad(w, x[:, i], y[:, i])\n",
    "        w -= lr*del_w\n",
    "        if epoch == next_print:\n",
    "            print(f'Iteration: {epoch}\\tAccuracy: {acc(w, x, y)}\\tW-norm: {np.linalg.norm(w)}')\n",
    "            next_print = min(2*epoch, num_epochs)\n",
    "    print(f'Final W: {w}')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptronloss(w, x, y):\n",
    "    score = np.dot(w, x)\n",
    "    guess = np.argmax(score)\n",
    "    correct_ans = np.argmax(y)\n",
    "    return score[guess] - score[correct_ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.5495103373231773\tW-norm: 0.0\n",
      "Iteration: 2\tAccuracy: 0.5495103373231773\tW-norm: 0.0\n",
      "Iteration: 4\tAccuracy: 0.4211099020674646\tW-norm: 5.290171870553924\n",
      "Iteration: 8\tAccuracy: 0.5625680087051143\tW-norm: 5.6661670938298325\n",
      "Iteration: 16\tAccuracy: 0.6974972796517954\tW-norm: 11.901057317936083\n",
      "Iteration: 32\tAccuracy: 0.940152339499456\tW-norm: 15.165438098332027\n",
      "Iteration: 64\tAccuracy: 0.9096844396082698\tW-norm: 26.37517203509059\n",
      "Iteration: 128\tAccuracy: 0.9064200217627857\tW-norm: 38.866815190865545\n",
      "Iteration: 256\tAccuracy: 0.8356909684439608\tW-norm: 51.32323597264314\n",
      "Iteration: 512\tAccuracy: 0.9521218715995647\tW-norm: 58.94075301787031\n",
      "Iteration: 1024\tAccuracy: 0.9608269858541894\tW-norm: 69.19395585091425\n",
      "Iteration: 2048\tAccuracy: 0.9532100108813928\tW-norm: 77.09464376684446\n",
      "Iteration: 4096\tAccuracy: 0.941240478781284\tW-norm: 84.00056980325063\n",
      "Iteration: 8192\tAccuracy: 0.9630032644178455\tW-norm: 95.09367460462087\n",
      "Iteration: 16384\tAccuracy: 0.9630032644178455\tW-norm: 83.00866609345572\n",
      "Iteration: 32768\tAccuracy: 0.9608269858541894\tW-norm: 94.73333777036254\n",
      "Iteration: 65536\tAccuracy: 0.9423286180631121\tW-norm: 99.46967538069036\n",
      "Iteration: 131072\tAccuracy: 0.9379760609357998\tW-norm: 97.26664631007647\n",
      "Iteration: 262144\tAccuracy: 0.9630032644178455\tW-norm: 91.1403581271648\n",
      "Iteration: 524288\tAccuracy: 0.9510337323177367\tW-norm: 102.49152764984208\n",
      "Iteration: 1048576\tAccuracy: 0.9173014145810664\tW-norm: 101.05915379387557\n",
      "Final W: [[ 45.4445898  33.224431   41.523365   14.601811 ]\n",
      " [-45.4445898 -33.224431  -41.523365  -14.601811 ]]\n"
     ]
    }
   ],
   "source": [
    "wperceptron2 = optimize(perceptronloss, banknote_x_train, banknote_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadraticloss(w, x, y):\n",
    "   return 0.5 * np.sum(np.square(np.abs(np.dot(w, x) - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.44940152339499456\tW-norm: 0.001085302968766251\n",
      "Iteration: 2\tAccuracy: 0.470076169749728\tW-norm: 0.0011531065278076419\n",
      "Iteration: 4\tAccuracy: 0.4733405875952122\tW-norm: 0.0017473255796710797\n",
      "Iteration: 8\tAccuracy: 0.5680087051142546\tW-norm: 0.0022678408433794003\n",
      "Iteration: 16\tAccuracy: 0.7388465723612623\tW-norm: 0.004769068841815052\n",
      "Iteration: 32\tAccuracy: 0.6800870511425462\tW-norm: 0.009713912342420746\n",
      "Iteration: 64\tAccuracy: 0.7573449401523396\tW-norm: 0.0161548517107483\n",
      "Iteration: 128\tAccuracy: 0.7290533188248096\tW-norm: 0.03363579621705654\n",
      "Iteration: 256\tAccuracy: 0.7562568008705114\tW-norm: 0.05859070637224487\n",
      "Iteration: 512\tAccuracy: 0.8313384113166485\tW-norm: 0.09747627366790566\n",
      "Iteration: 1024\tAccuracy: 0.9031556039173014\tW-norm: 0.15198118414721798\n",
      "Iteration: 2048\tAccuracy: 0.9477693144722524\tW-norm: 0.21298300734927483\n",
      "Iteration: 4096\tAccuracy: 0.9532100108813928\tW-norm: 0.2533507780288085\n",
      "Iteration: 8192\tAccuracy: 0.9423286180631121\tW-norm: 0.2677176431544285\n",
      "Iteration: 16384\tAccuracy: 0.941240478781284\tW-norm: 0.27250349535231444\n",
      "Iteration: 32768\tAccuracy: 0.9445048966267682\tW-norm: 0.27493872482008064\n",
      "Iteration: 65536\tAccuracy: 0.9423286180631121\tW-norm: 0.2698986800279752\n",
      "Iteration: 131072\tAccuracy: 0.9499455930359086\tW-norm: 0.2711711354200628\n",
      "Iteration: 262144\tAccuracy: 0.9499455930359086\tW-norm: 0.26965626588370295\n",
      "Iteration: 524288\tAccuracy: 0.9445048966267682\tW-norm: 0.27303091269114377\n",
      "Iteration: 1048576\tAccuracy: 0.9423286180631121\tW-norm: 0.27394844611253105\n",
      "Final W: [[ 0.16492459  0.09536264  0.13342381 -0.02810317]\n",
      " [-0.06947794 -0.02071742  0.0267577  -0.11911979]]\n"
     ]
    }
   ],
   "source": [
    "wadaline2 = optimize(quadraticloss, banknote_x_train, banknote_y_train, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL(w, x, y):\n",
    "    probs = np.exp(np.dot(w, x))\n",
    "    probs /= np.sum(probs)\n",
    "    correct_ans = np.argmax(y)\n",
    "    return -np.log(probs[correct_ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\tAccuracy: 0.6528835690968444\tW-norm: 0.07269255326011799\n",
      "Iteration: 2\tAccuracy: 0.7736670293797606\tW-norm: 0.07333482222414799\n",
      "Iteration: 4\tAccuracy: 0.7671381936887922\tW-norm: 0.1171861871711065\n",
      "Iteration: 8\tAccuracy: 0.7377584330794341\tW-norm: 0.13550389541116678\n",
      "Iteration: 16\tAccuracy: 0.7878128400435256\tW-norm: 0.22137849556195635\n",
      "Iteration: 32\tAccuracy: 0.8019586507072906\tW-norm: 0.3095547983674853\n",
      "Iteration: 64\tAccuracy: 0.9064200217627857\tW-norm: 0.46598069359307953\n",
      "Iteration: 128\tAccuracy: 0.9575625680087051\tW-norm: 0.6853846698130158\n",
      "Iteration: 256\tAccuracy: 0.9336235038084875\tW-norm: 0.8938131235835516\n",
      "Iteration: 512\tAccuracy: 0.926006528835691\tW-norm: 1.1536524591459862\n",
      "Iteration: 1024\tAccuracy: 0.9640914036996736\tW-norm: 1.4497994229937088\n",
      "Iteration: 2048\tAccuracy: 0.9619151251360174\tW-norm: 1.7618215742362024\n",
      "Iteration: 4096\tAccuracy: 0.9532100108813928\tW-norm: 2.1128853649671084\n",
      "Iteration: 8192\tAccuracy: 0.955386289445049\tW-norm: 2.501855243457162\n",
      "Iteration: 16384\tAccuracy: 0.9586507072905331\tW-norm: 2.8633553036156965\n",
      "Iteration: 32768\tAccuracy: 0.9630032644178455\tW-norm: 3.0210540188273103\n",
      "Iteration: 65536\tAccuracy: 0.9640914036996736\tW-norm: 3.0390256134706197\n",
      "Iteration: 131072\tAccuracy: 0.9619151251360174\tW-norm: 3.185590371886836\n",
      "Iteration: 262144\tAccuracy: 0.9640914036996736\tW-norm: 3.2061516585769314\n",
      "Iteration: 524288\tAccuracy: 0.9630032644178455\tW-norm: 3.248111096620591\n",
      "Iteration: 1048576\tAccuracy: 0.9630032644178455\tW-norm: 3.1811793362848415\n",
      "Final W: [[ 1.61835349  1.04561566  1.0575578   0.47868816]\n",
      " [-1.61835349 -1.04561566 -1.0575578  -0.47868816]]\n"
     ]
    }
   ],
   "source": [
    "wsoftmax2 = optimize(NLL, banknote_x_train, banknote_y_train, lr = 0.01)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecd819018ed349fe3690ec2e670a812dd1f7ce5ef76093a52a4dd523668f0c5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
